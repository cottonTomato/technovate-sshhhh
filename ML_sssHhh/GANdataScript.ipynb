{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Exception encountered when calling Functional.call().\\n\\n\\x1b[1m1634545486880\\x1b[0m\\n\\nArguments received by Functional.call():\\n  • inputs=tf.Tensor(shape=(3, 7, 14), dtype=float32)\\n  • training=False\\n  • mask=None'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 264\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# Run this in a separate cell\u001b[39;00m\n\u001b[1;32m--> 264\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_and_visualize_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 247\u001b[0m, in \u001b[0;36mgenerate_and_visualize_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;66;03m# Generate data\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating synthetic data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 247\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_time_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_days\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 193\u001b[0m, in \u001b[0;36mCarbonFootprintGenerator.generate_time_series\u001b[1;34m(self, num_days)\u001b[0m\n\u001b[0;32m    190\u001b[0m normalized_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize_data(df[numerical_cols])\n\u001b[0;32m    192\u001b[0m \u001b[38;5;66;03m# Generate variations\u001b[39;00m\n\u001b[1;32m--> 193\u001b[0m variations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormalized_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# Combine original and variations\u001b[39;00m\n\u001b[0;32m    196\u001b[0m final_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_data(df, variations, numerical_cols)\n",
      "File \u001b[1;32md:\\Technovate\\New folder\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\Technovate\\New folder\\venv\\Lib\\site-packages\\keras\\src\\ops\\function.py:179\u001b[0m, in \u001b[0;36mFunction._run_through_graph\u001b[1;34m(self, inputs, operation_fn, call_fn)\u001b[0m\n\u001b[0;32m    177\u001b[0m output_tensors \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs:\n\u001b[1;32m--> 179\u001b[0m     output_tensors\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtensor_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mpack_sequence_as(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_struct, output_tensors)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Exception encountered when calling Functional.call().\\n\\n\\x1b[1m1634545486880\\x1b[0m\\n\\nArguments received by Functional.call():\\n  • inputs=tf.Tensor(shape=(3, 7, 14), dtype=float32)\\n  • training=False\\n  • mask=None'"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import seaborn as sns\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "class CarbonFootprintGenerator:\n",
    "    def __init__(self):\n",
    "        # Define base profiles\n",
    "        self.base_profiles = [\n",
    "            {\n",
    "                \"individual_id\": \"ECO001\",\n",
    "                \"name\": \"Alex Green\",\n",
    "                \"body_type\": \"normal\",\n",
    "                \"sex\": \"female\",\n",
    "                \"diet\": \"vegetarian\",\n",
    "                \"occupation\": \"professional\",\n",
    "                \"lifestyle\": \"active\",\n",
    "                \"vehicle_type\": \"hybrid\"\n",
    "            },\n",
    "            {\n",
    "                \"individual_id\": \"ECO002\",\n",
    "                \"name\": \"Sam Chen\",\n",
    "                \"body_type\": \"overweight\",\n",
    "                \"sex\": \"male\",\n",
    "                \"diet\": \"omnivore\",\n",
    "                \"occupation\": \"student\",\n",
    "                \"lifestyle\": \"moderate\",\n",
    "                \"vehicle_type\": \"petrol\"\n",
    "            },\n",
    "            {\n",
    "                \"individual_id\": \"ECO003\",\n",
    "                \"name\": \"Maya Patel\",\n",
    "                \"body_type\": \"normal\",\n",
    "                \"sex\": \"female\",\n",
    "                \"diet\": \"vegan\",\n",
    "                \"occupation\": \"professional\",\n",
    "                \"lifestyle\": \"active\",\n",
    "                \"vehicle_type\": \"electric\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Define activity parameters\n",
    "        self.activity_ranges = {\n",
    "            \"distance_km\": (5, 50),\n",
    "            \"tv_pc_hours\": (1, 8),\n",
    "            \"internet_hours\": (1, 10),\n",
    "            \"cooking_hours\": (0.5, 3),\n",
    "            \"grocery_spending\": (10, 100),\n",
    "            \"waste_bags\": (1, 3)\n",
    "        }\n",
    "        \n",
    "        # Build VAE\n",
    "        self.vae = self._build_vae()\n",
    "        \n",
    "    def _build_vae(self):\n",
    "        # Number of features we'll track\n",
    "        n_features = 14  # Adjusted to match our actual features\n",
    "        \n",
    "        # Encoder\n",
    "        encoder_inputs = keras.Input(shape=(7, n_features))\n",
    "        x = layers.LSTM(32, return_sequences=True)(encoder_inputs)\n",
    "        x = layers.LSTM(16)(x)\n",
    "        \n",
    "        # Latent space\n",
    "        latent_dim = 8\n",
    "        z_mean = layers.Dense(latent_dim)(x)\n",
    "        z_log_var = layers.Dense(latent_dim)(x)\n",
    "        \n",
    "        # Sampling layer\n",
    "        def sampling(args):\n",
    "            z_mean, z_log_var = args\n",
    "            epsilon = tf.random.normal(shape=tf.shape(z_mean))\n",
    "            return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "        \n",
    "        z = layers.Lambda(sampling)([z_mean, z_log_var])\n",
    "        \n",
    "        # Decoder\n",
    "        decoder_inputs = keras.Input(shape=(latent_dim,))\n",
    "        x = layers.Dense(16)(decoder_inputs)\n",
    "        x = layers.RepeatVector(7)(x)\n",
    "        x = layers.LSTM(32, return_sequences=True)(x)\n",
    "        decoder_outputs = layers.TimeDistributed(layers.Dense(n_features))(x)\n",
    "        \n",
    "        # Create models\n",
    "        vae = keras.Model(encoder_inputs, decoder_outputs)\n",
    "        vae.compile(optimizer='adam', loss='mse')\n",
    "        \n",
    "        return vae\n",
    "    \n",
    "    def generate_daily_activities(self, profile, date, is_weekend):\n",
    "        \"\"\"Generate realistic daily activities for an individual\"\"\"\n",
    "        \n",
    "        # Base multipliers based on profile\n",
    "        lifestyle_multiplier = {\n",
    "            \"active\": 1.2,\n",
    "            \"moderate\": 1.0,\n",
    "            \"sedentary\": 0.8\n",
    "        }.get(profile[\"lifestyle\"], 1.0)\n",
    "        \n",
    "        # Weekend multiplier\n",
    "        weekend_multiplier = 1.3 if is_weekend else 1.0\n",
    "        \n",
    "        # Generate activities with realistic variations\n",
    "        def vary(base, range_tuple):\n",
    "            min_val, max_val = range_tuple\n",
    "            base_val = np.random.uniform(min_val, max_val)\n",
    "            return base_val * lifestyle_multiplier * weekend_multiplier * np.random.normal(1, 0.1)\n",
    "        \n",
    "        activities = {\n",
    "            \"date\": date.strftime(\"%Y-%m-%d\"),\n",
    "            \"distance_km\": vary(20, self.activity_ranges[\"distance_km\"]),\n",
    "            \"tv_pc_hours\": vary(4, self.activity_ranges[\"tv_pc_hours\"]),\n",
    "            \"internet_hours\": vary(5, self.activity_ranges[\"internet_hours\"]),\n",
    "            \"cooking_hours\": vary(1.5, self.activity_ranges[\"cooking_hours\"]),\n",
    "            \"grocery_spending\": vary(40, self.activity_ranges[\"grocery_spending\"]),\n",
    "            \"waste_bags\": round(vary(1.5, self.activity_ranges[\"waste_bags\"])),\n",
    "            \"meals_vegetarian\": 3 if profile[\"diet\"] in [\"vegetarian\", \"vegan\"] else np.random.randint(0, 2),\n",
    "            \"meals_meat\": 0 if profile[\"diet\"] in [\"vegetarian\", \"vegan\"] else np.random.randint(1, 3),\n",
    "            \"meals_processed\": np.random.randint(0, 2),\n",
    "            \"indoor_activity_hours\": vary(3, (2, 6)),\n",
    "            \"outdoor_activity_hours\": vary(2, (1, 4)),\n",
    "            \"public_transport\": int(np.random.random() > 0.7),\n",
    "            \"air_travel\": int(np.random.random() > 0.95),\n",
    "        }\n",
    "        \n",
    "        # Calculate carbon footprint\n",
    "        activities[\"carbon_footprint\"] = self._calculate_footprint(activities, profile)\n",
    "        \n",
    "        return activities\n",
    "    \n",
    "    def _calculate_footprint(self, activities, profile):\n",
    "        \"\"\"Calculate carbon footprint based on activities\"\"\"\n",
    "        footprint = 0\n",
    "        \n",
    "        # Transport emissions\n",
    "        vehicle_emissions = {\n",
    "            \"petrol\": 0.2,\n",
    "            \"diesel\": 0.18,\n",
    "            \"hybrid\": 0.12,\n",
    "            \"electric\": 0.05\n",
    "        }\n",
    "        footprint += activities[\"distance_km\"] * vehicle_emissions.get(profile[\"vehicle_type\"], 0.15)\n",
    "        \n",
    "        # Energy usage\n",
    "        footprint += (activities[\"tv_pc_hours\"] + activities[\"internet_hours\"]) * 0.1\n",
    "        footprint += activities[\"cooking_hours\"] * 0.5\n",
    "        \n",
    "        # Food emissions\n",
    "        footprint += activities[\"meals_meat\"] * 3.0\n",
    "        footprint += activities[\"meals_processed\"] * 2.0\n",
    "        footprint += activities[\"meals_vegetarian\"] * 1.0\n",
    "        \n",
    "        # Add some random variation\n",
    "        footprint *= np.random.normal(1, 0.05)\n",
    "        \n",
    "        return round(footprint, 2)\n",
    "    \n",
    "    def generate_time_series(self, num_days=7):\n",
    "        \"\"\"Generate time series data for all individuals\"\"\"\n",
    "        start_date = datetime.now() - timedelta(days=num_days)\n",
    "        all_data = []\n",
    "        \n",
    "        for profile in self.base_profiles:\n",
    "            individual_data = []\n",
    "            \n",
    "            for day in range(num_days):\n",
    "                current_date = start_date + timedelta(days=day)\n",
    "                is_weekend = current_date.weekday() >= 5\n",
    "                \n",
    "                daily_data = self.generate_daily_activities(profile, current_date, is_weekend)\n",
    "                daily_data.update(profile)  # Add profile information\n",
    "                individual_data.append(daily_data)\n",
    "            \n",
    "            all_data.extend(individual_data)\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame(all_data)\n",
    "        \n",
    "        # Generate additional variations using VAE\n",
    "        numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        normalized_data = self._normalize_data(df[numerical_cols])\n",
    "        \n",
    "        # Generate variations\n",
    "        variations = self.vae.predict(normalized_data)\n",
    "        \n",
    "        # Combine original and variations\n",
    "        final_df = self._combine_data(df, variations, numerical_cols)\n",
    "        \n",
    "        return final_df\n",
    "    \n",
    "    def _normalize_data(self, df):\n",
    "        \"\"\"Normalize numerical data for VAE\"\"\"\n",
    "        normalized = df.copy()\n",
    "        for col in df.columns:\n",
    "            normalized[col] = (df[col] - df[col].mean()) / (df[col].std() + 1e-10)\n",
    "        # Ensure the shape matches the expected input shape for the VAE\n",
    "        return normalized.values.reshape(-1, 7, len(df.columns))\n",
    "    \n",
    "    def _combine_data(self, original_df, variations, numerical_cols):\n",
    "        \"\"\"Combine original data with VAE variations\"\"\"\n",
    "        variations = variations.reshape(-1, len(numerical_cols))\n",
    "        variations_df = pd.DataFrame(variations, columns=numerical_cols)\n",
    "        \n",
    "        # Copy non-numerical columns\n",
    "        for col in original_df.columns:\n",
    "            if col not in numerical_cols:\n",
    "                variations_df[col] = original_df[col].values\n",
    "        \n",
    "        return pd.concat([original_df, variations_df], ignore_index=True)\n",
    "    \n",
    "    def plot_time_series(self, df):\n",
    "        \"\"\"Plot time series data\"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        # Plot carbon footprint over time for each individual\n",
    "        for individual in df['individual_id'].unique():\n",
    "            individual_data = df[df['individual_id'] == individual]\n",
    "            plt.plot(pd.to_datetime(individual_data['date']), \n",
    "                    individual_data['carbon_footprint'], \n",
    "                    label=f\"{individual_data['name'].iloc[0]}\")\n",
    "        \n",
    "        plt.title('Daily Carbon Footprint by Individual')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Carbon Footprint (kg CO2)')\n",
    "        plt.legend()\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        return plt.gcf()\n",
    "\n",
    "# Usage example (copy this to a new cell to run)\n",
    "def generate_and_visualize_data():\n",
    "    # Initialize generator\n",
    "    generator = CarbonFootprintGenerator()\n",
    "    \n",
    "    # Generate data\n",
    "    print(\"Generating synthetic data...\")\n",
    "    df = generator.generate_time_series(num_days=7)\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(\"carbon_footprint_timeseries.csv\", index=False)\n",
    "    print(\"Data saved to 'carbon_footprint_timeseries.csv'\")\n",
    "    \n",
    "    # Create visualization\n",
    "    fig = generator.plot_time_series(df)\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\nSummary Statistics:\")\n",
    "    print(df.describe())\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Run this in a separate cell\n",
    "df = generate_and_visualize_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
